# Доменная RAG система на Национальных Казахстанских источниках

# 1. Проблематика

## A. Большие языковые модели неэффективны в узкоспециализированных областях

**Галлюцинирование** - главная проблема при работе в узкоспециализированной области

**Отсутствие воспроизводимости** - нет возможности проверить информацию, запросив автора-работу-страницу

**Недостоверность источников** - использование Wikipedia или медиаисточников 
нерелевантно в узкоспециализированной академической области

## B. PDF формат

**Наиболее шумный**

**Создан для человека, а не алгоритма**

**Опирается исключительно на эвристическую модель, а не бинарную**

# 2. Цель проекта

**Реализовать систему**, в которой LLM выступает как интерпретатор источников

**Система позволяет**:
- Проверить каждый источник
- Запросить цитату 
- Произвести анализ-сравнение источников

# 3. Результат (demo) 

## Выводы системы:

**Система дает качественную доменную справку**: [rag_answer_1](demo/rag_answer_1.png)

**Система анализирует источники**: [rag_answer_2](demo/rag_answer_2.png)  (трактовка "опера Биржан-сал" не мешает найти каноничное название оперы - "Биржан и Сара")

**Система цитирует источники**: [rag_answer_3](demo/rag_answer_3.png)

**Лог результата поиска Retrieval**: [retrieval_example](demo/retrieval_example.png)

# 4. Реализация проекта

## Offline block

### A. Document Corpus

**Составление уникального доменного корпуса PDF-документов**, включающего:
**Казахскую музыкальную литературу**, а также:
- Мировую музыкальную литературу
- Русскую музыкальную литературу

### B. PDF to Text Pipeline

**Создание OCR слоя для PDF-источников**:
- Самостоятельно с помощью OCR-движка `tesseract`.
- `.png` преобразовывается в бинарный формат `CCITT group 4`
- `Matrix(3, 3)` позволяет не потерять в качестве OCR

**Parsing**

Реализация парсинга подробнее разобрана в [parser_protocol.md](docs/parser_protocol.md) и [parsing_heuristics.md](docs/parsing_heuristics.md)

Кратко:
- Использование PDF-движка `mupdf/fitz`
с параметром `dict` для качественного эвристического отсева большей части шума (нотных иллюстраций, фото)

### C. Semantic Chunking

**Токенизация текста** с помощью:
- Словаря embedding-модели `multilingual-e5`
- Метода `AutoTokenizer` библиотеки `transformers`

**Чанкинг по токенам** происходит путем итератора с **окном перекрытия**

Сохранение метаданных с помощью:
- `offsets` от `Tokenizer`
- написанного `mapping`


### D. Embeddings

**Создание эмбеддингов** осуществляется с помощью эмбеддинг-модели `multilingual-e5`

## Online block

### A. User Query 

**Создается вектор** запроса пользователя

### B. Semantic Retrieval

**Семантическое сопоставление `query` и `embeddings`** происходит с помощью методов:
- `cosine similarity`
- `IndexFlatIP` индексатора `FAISS`. С помощью него же происходит фильтрация по `top-k`

### C. LLM Answer Generation

**Модель**: `Qwen3:8B` размещенная локально

Модель выступает как **интерпретатор** данных, которые выдал `retrieval`

### Latency
**Узким горлышком** времени ответа является генерация токенов LLM. 

**Без стриминга токенов задержка** составляет **8-10 сек**, с пиками до 12 сек на ответ

**Использование режима без стриминга** обусловлено `Telegram-UI`

# Контакты

**Telegram**: https://t.me/scuffy_kid

**Email**: karona7560@gmail.com 
